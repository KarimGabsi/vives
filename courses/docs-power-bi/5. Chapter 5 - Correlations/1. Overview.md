---
sidebar_position: 1
---

# Overview
:::note
Sources

ncl.ac.uk:
[1](https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/types-of-correlation.html)
[2](https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/strength-of-correlation.html)

wikipedia:
[Bradfor Hill](https://en.wikipedia.org/wiki/Bradford_Hill_criteria)
[DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph)
[Multivariate](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)
[Markov](https://en.wikipedia.org/wiki/Markov_model)

books and such:
[Bradfor Hill - Chapter 13 (1995)] (https://epiville.ccnmtl.columbia.edu/assets/pdfs/Hill_1965.pdf)
[Judea Pearl - Causality] (https://yzhu.io/courses/core/reading/04.causality.pdf)

:::

## What is a correlation?

Correlation describes the relationship between variables. 
It can be described as either strong or weak, and as either positive or negative.

## What is causation?

The relationship between cause and effect.


## Correlation vs Causation:

:::danger
It is very important to know that correlation does **not necessarily** mean causation
:::


## Types

In statistics, the consensus is that there are four types of correlations:

1. Positive Linear Correlation
2. Negative Linear Correlation
3. Non-linear Correlation
4. No Correlation

## Coefficient

"However, it is not always as easy to tell just by looking at the scatter graph, instead we quantify it using a numeric value known as **the correlation coefficient**."

There are several correlation coefficients that we can use, each has their own uses. 
We're exploring four of them:

1. Pearson correlation
2. Kendall-rank correlation
3. Spearman correlation
4. Point-biserial correlation

## When does a correlation become a causation?

### Bradford Hill

In 1965, the English statistician Sir Austin Bradford Hill proposed a set of nine criteria to provide epidemiologic evidence of a causal relationship between a presumed cause and an observed effect. <br />
For example, he demonstrated the connection between cigarette smoking and lung cancer.) 

The list of the criteria is as follows:

- Strength (effect size): <br />
A small association does not mean that there is not a causal effect, though the larger the association, the more likely that it is causal.
- Consistency (reproducibility): <br />
Consistent findings observed by different persons in different places with different samples strengthens the likelihood of an effect.
- Specificity: <br />
Causation is likely if there is a very specific population at a specific site and disease with no other likely explanation. The more specific an association between a factor and an effect is, the bigger the probability of a causal relationship.[1]
- Temporality: <br />
The effect has to occur after the cause (and if there is an expected delay between the cause and expected effect, then the effect must occur after that delay).
- Biological gradient (dose–response relationship):  <br />
Greater exposure should generally lead to greater incidence of the effect. However, in some cases, the mere presence of the factor can trigger the effect. In other cases, an inverse proportion is observed: greater exposure leads to lower incidence.[1]
- Plausibility:  <br />
A plausible mechanism between cause and effect is helpful (but Hill noted that knowledge of the mechanism is limited by current knowledge).
- Coherence:  <br />
Coherence between epidemiological and laboratory findings increases the likelihood of an effect. However, Hill noted that "lack of such [laboratory] evidence cannot nullify the epidemiological effect on associations".
- Experiment:  <br />
"Occasionally it is possible to appeal to experimental evidence".
- Analogy:  <br />
The use of analogies or similarities between the observed association and any other associations.

Example: [PDF, Bradford Hill - Chapter 13](https://epiville.ccnmtl.columbia.edu/assets/pdfs/Hill_1965.pdf)

#### Reversibility

Theory summed up: "If the cause is deleted then the effect should disappear as well."

### Judea Pearl

#### Causel VS Statistitical Terminology

[p. 38: 1.5 CAUSAL VERSUS STATISTICAL TERMINOLOGY](https://yzhu.io/courses/core/reading/04.causality.pdf) <br /> 

##### Parameters

- A probabilistic parameter is any quantity that is defined in terms of a joint probability function.
- A statistical parameter is any quantity that is defined in terms of a joint probability distribution of observed variables, making no assumption whatsoever regarding the
existence or nonexistence of unobserved variables.
- A causal parameter is any quantity that is defined in terms of a causal model and is not a statistical parameter

#### Assumptions

##### Statistical Assumption

A statistical assumption is any constraint on a joint distribution of observed variable; <br />
for example, that $$f$$ is [multivariate normal](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) or that $$P$$ is [Markov relative](https://en.wikipedia.org/wiki/Markov_model) to a given [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph) $$D$$.

###### Examples

Examples of statistical concepts are: correlation, regression, conditional independence, association, likelihood,
collapsibility, risk ratio, odds ratio, propensity score, Granger’s causality, and so on.

##### Causal Assumption

A causal assumption is any constraint on a causal model that cannot be realized by imposing statistical assumptions; <br />
for example, that $$fi$$ is linear, that $$Ui$$ and $$Uj$$ (unobserved) are uncorrelated, or that $$x3$$ does not appear in $$f4(pa4, u4)$$.

###### Examples

Examples of causal concepts are: randomization, influence, effect, confounding, exogeneity, ignorability, disturbance, spurious correlation, path coefficients,
instrumental variables, intervention, explanation, and so on. 

#### Causal Analysis

The sharp distinction between statistical and causal concepts can be translated into a <br />
useful principle: **behind every causal claim there must lie some causal assumption that <br />
is not discernable from the joint distribution and, hence, not testable in observational studies.** <br />

Such assumptions are usually provided by humans, resting on expert `judgment`. <br />
Thus, the way humans organize and communicate experiential knowledge becomes an
integral part of the study, for it determines the veracity of the judgments experts are
requested to articulate.  <br />

Another <u>ramification</u> of this causal–statistical distinction is that any mathematical <br />
approach to causal analysis must acquire new notation. <br />
The vocabulary of probability calculus, with its powerful operators of expectation, conditionalization, and marginalization, is defined strictly in terms of distribution functions and is therefore insufficient for expressing causal assumptions or causal claims. <br />

To illustrate, the syntax of probability calculus does not permit us to express the simple fact that “symptoms do not cause
diseases", let alone draw mathematical conclusions from such facts. <br />
**All we can say is that two events are dependent** – meaning that if we find one, we can expect to encounter
the other, **but we cannot distinguish statistical dependence**, quantified by the conditional probability $$P(disease ƒ symptom)$$,<br />
from causal dependence, for which we have no expression in standard probability calculus.  <br />

The preceding two requirements: 
1. To commence causal analysis with untested judgmental assumptions
2. To extend the syntax of probability calculus constitute

the two main obstacles to the acceptance of causal analysis among professionals with
traditional training in statistics (Pearl 2003c, also sections 11.1.1 and 11.6.4).

#### Causel Model

##### \[p.44] Definition 2.2.1. (Causal Structure):

A causal structure of a set of variables V is a directed acyclic graph (DAG) in which each
node corresponds to a distinct element of V, and each link represents a direct functional
relationship among the corresponding variables.

A causal structure serves as a blueprint for forming a “causal model” – a precise specification of how each variable is influenced by its parents in the DAG, as in the structural
equation model of 
$$
xi  = fi(pai, ui)\ and\ i = 1,..., n 
$$
where $$pai$$ (connoting parents) stands for the set of variables that directly determine the value of $$Xi$$ <br />
and where the $$Ui$$ represent errors (or “disturbances”) due to omitted factors <br />

**Here we assume that Nature is at liberty to impose arbitrary functional relationships between each effect and its causes and then to perturb these relationships by introducing arbitrary (yet mutually independent) disturbances. <br />
These disturbances reflect “hidden” or unmeasurable conditions that Nature governs by some undisclosed probability function.**

[In a nutshell](https://stats.stackexchange.com/a/538): <i>"Look for hidden variables. If there is a hidden variable that happens not to vary in the measured sample, then the correlation would not imply causation. Expose all hidden variables and you have causation."</i>


