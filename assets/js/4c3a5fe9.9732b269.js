"use strict";(self.webpackChunkcourses=self.webpackChunkcourses||[]).push([[4129],{4137:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>d});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var p=n.createContext({}),s=function(e){var t=n.useContext(p),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},c=function(e){var t=s(e.components);return n.createElement(p.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,p=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=s(r),d=a,f=m["".concat(p,".").concat(d)]||m[d]||u[d]||o;return r?n.createElement(f,i(i({ref:t},c),{},{components:r})):n.createElement(f,i({ref:t},c))}));function d(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=m;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var s=2;s<o;s++)i[s]=r[s];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},6438:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>s});var n=r(7462),a=(r(7294),r(4137));const o={sidebar_position:1},i="Official Tutorial + Exercise",l={unversionedId:"Chapter 6 - Scrapy/official tutorial",id:"Chapter 6 - Scrapy/official tutorial",title:"Official Tutorial + Exercise",description:"Documentation: docs",source:"@site/docs-cloud-for-ai/Chapter 6 - Scrapy/1. official tutorial.md",sourceDirName:"Chapter 6 - Scrapy",slug:"/Chapter 6 - Scrapy/official tutorial",permalink:"/vives/docs-cloud-for-ai/Chapter 6 - Scrapy/official tutorial",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Summary Exercise: Guide",permalink:"/vives/docs-cloud-for-ai/Chapter 5 - Summary Excercise/guide"},next:{title:"Final Assignment",permalink:"/vives/docs-cloud-for-ai/Chapter 7 - Final Assignment/final assignment"}},p={},s=[{value:"Installation",id:"installation",level:2},{value:"Creating a Spider",id:"creating-a-spider",level:2},{value:"Running the Spider",id:"running-the-spider",level:2},{value:"Method from the official tutorial page",id:"method-from-the-official-tutorial-page",level:3},{value:"The Python way!",id:"the-python-way",level:3},{value:"Exercise",id:"exercise",level:2}],c={toc:s};function u(e){let{components:t,...r}=e;return(0,a.kt)("wrapper",(0,n.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"official-tutorial--exercise"},"Official Tutorial + Exercise"),(0,a.kt)("admonition",{type:"note"},(0,a.kt)("p",{parentName:"admonition"},"Documentation: ",(0,a.kt)("a",{parentName:"p",href:"https://docs.scrapy.org/en/latest/"},"docs")," ",(0,a.kt)("br",null),"\nOfficial tutorial: ",(0,a.kt)("a",{parentName:"p",href:"https://docs.scrapy.org/en/latest/intro/tutorial.html"},"official tutorial")," ",(0,a.kt)("br",null),"\nQuotes-bot: ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/scrapy/quotesbot"},"github")," ",(0,a.kt)("br",null))),(0,a.kt)("h2",{id:"installation"},"Installation"),(0,a.kt)("p",null,"1) Open pycharm and start a new project with a virtual environment. ",(0,a.kt)("br",null),"\n2) Install ",(0,a.kt)("inlineCode",{parentName:"p"},"Scrapy")," ",(0,a.kt)("br",null),"\n3) Find ",(0,a.kt)("em",{parentName:"p"},"scrapy.exe")," in your scripts folder ",(0,a.kt)("br",null),"\nExample: C:\\Users","{","username}\\PycharmProjects\\Scrapy\\venv\\Scripts","\\",(0,a.kt)("strong",{parentName:"p"},"Scrapy.exe")),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"In pycharm you can right-click on a file and select ",(0,a.kt)("strong",{parentName:"p"},"Copy Path/Reference..."))),(0,a.kt)("p",null,"4) Copy the path and go to your terminal ",(0,a.kt)("strong",{parentName:"p"},"within")," the same project  ",(0,a.kt)("br",null),"\n5) Execute the command:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-text"},"C:\\Users\\{username}\\PycharmProjects\\Scrapy\\venv\\Scripts\\Scrapy.exe startproject tutorial\n")),(0,a.kt)("p",null,"By now you should have a tutorial folder in your project with the following layout:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-text"},"tutorial/\n    scrapy.cfg            # deploy configuration file\n\n    tutorial/             # project's Python module, you'll import your code from here\n        __init__.py\n\n        items.py          # project items definition file\n\n        middlewares.py    # project middlewares file\n\n        pipelines.py      # project pipelines file\n\n        settings.py       # project settings file\n\n        spiders/          # a directory where you'll later put your spiders\n            __init__.py\n")),(0,a.kt)("h2",{id:"creating-a-spider"},"Creating a Spider"),(0,a.kt)("admonition",{type:"danger"},(0,a.kt)("p",{parentName:"admonition"},"When making a Spider, don't forget to inherit from the Spider-Class")),(0,a.kt)("p",null,"In ",(0,a.kt)("inlineCode",{parentName:"p"},"tutorial/spiders")," create a quotes_spider.py file:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python",metastring:'title="quotes_spider.py"',title:'"quotes_spider.py"'},"import scrapy\n\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n\n    def start_requests(self):\n        urls = [\n            'https://quotes.toscrape.com/page/1/',\n            'https://quotes.toscrape.com/page/2/',\n        ]\n        for url in urls:\n            yield scrapy.Request(url=url, callback=self.parse)\n\n    def parse(self, response):\n        page = response.url.split(\"/\")[-2]\n        filename = f'quotes-{page}.html'\n        with open(filename, 'wb') as f:\n            f.write(response.body)\n        self.log(f'Saved file {filename}')\n")),(0,a.kt)("h2",{id:"running-the-spider"},"Running the Spider"),(0,a.kt)("h3",{id:"method-from-the-official-tutorial-page"},"Method from the official tutorial page"),(0,a.kt)("p",null,"Go to your project terminal and execute the following line:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-text"},"C:\\Users\\{username}\\PycharmProjects\\Scrapy\\venv\\Scripts\\Scrapy.exe crawl quotes\n")),(0,a.kt)("h3",{id:"the-python-way"},"The Python way!"),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"Scrapy from scripts: ",(0,a.kt)("a",{parentName:"p",href:"https://docs.scrapy.org/en/latest/topics/practices.html"},"docs"))),(0,a.kt)("p",null,"1) open ",(0,a.kt)("inlineCode",{parentName:"p"},"main.py")," from your project (delete everything if you have the template version)"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"if __name__ == '__main__':\n    pass\n")),(0,a.kt)("p",null,"2) import the ",(0,a.kt)("inlineCode",{parentName:"p"},"CrawlerProcess")," & your ",(0,a.kt)("inlineCode",{parentName:"p"},"QuotesSpider"),"-class"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from tutorial.tutorial.spiders.quotes_spider import QuotesSpider\nfrom scrapy.crawler import CrawlerProcess\n")),(0,a.kt)("p",null,"3) Use the crawler:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from tutorial.tutorial.spiders.quotes_spider import QuotesSpider\nfrom scrapy.crawler import CrawlerProcess\n\nif __name__ == '__main__':\n    cp = CrawlerProcess()\n    cp.crawl(QuotesSpider)\n    cp.start()\n\n")),(0,a.kt)("p",null,"4) import our project settings"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from scrapy.utils.project import get_project_settings\n")),(0,a.kt)("p",null,"5) modify our code to use our project settings and run!"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from tutorial.tutorial.spiders.quotes_spider import QuotesSpider\nfrom scrapy.crawler import CrawlerProcess\nfrom scrapy.utils.project import get_project_settings\n\nif __name__ == '__main__':\n    config = get_project_settings()\n    cp = CrawlerProcess(settings=config)\n    cp.crawl(QuotesSpider)\n    cp.start()\n")),(0,a.kt)("h2",{id:"exercise"},"Exercise"),(0,a.kt)("p",null,"Create a new quotes-spider class and name it ",(0,a.kt)("strong",{parentName:"p"},"quotesclassified"),".\nIt should be able to do the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Modify your class to be able to receive a variable in order to scrape an n-amount of pages. ",(0,a.kt)("br",null),"\nSet n = 0 as a default. If the default is enabled, scrape all the pages possible."),(0,a.kt)("li",{parentName:"ul"},"The example saves the extracted data as html file, so modify your code in order to do the following:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Scrape quotes with their according tags / author."),(0,a.kt)("li",{parentName:"ul"},"Save the extracted data in a CSV file.")))))}u.isMDXComponent=!0}}]);